orenbm21, jirsch
Oren BenMeir (200143139), Jonathan Hirsch (200357697)
Ex: 4

FILES:
CachingFileSystem.cpp - the main lybrary program
CacheState.h - defines the CachBlock & PrivaetData structs
Logger.h - responsible for logging
Logger.cpp - same
Makefile
README

REMARKS:

Since most of the library function are almost identical to bbfs we'll write about caching_read:

In this function we first log the path, check that the offset is valid and calculate
the number of blocks that we'll be reading from.

As for the reading part: we first go over the cache and check if there is a block
with content from the file and range of bytes that we're reading from, in order
to avoid deleting it from the cache and re-reading it.

after reading from the cache we check if we still need to read more data and if so,
we read it from the disc using pread, and storing the blocks in the cache (using the LFU 
mechanism). 

The blocks are stored in the cache as an array of pointers.


ANSWERS:

1) Yes, the cache is saved in the RAM (Random Access Memory) and it takes nanoseconds to read 
from or write to, while access speed to and from the disc is measured in milliseconds. 
Therefore, it's about 100,000 times faster to read from the cache.

2) As mentioned in the question, there is no one answer. In an array-based implementation the 
modification of the counter is fast but the search for the LFU is not. In a Sorted List based 
implementation it's exactly the opposite. Therefore, if we know that we will read mostly from 
some files that will be in the cache it is better to use and array, so that we'll need mostly 
to modify the counter, rather than read from the disc. Otherwise, if we know that we'll read 
from many different files, so we'll need to read a lot from the disc, it's better to use the 
Sorted List based implementation.

3) Using the buffer cache may be harder to mangage for swapping pages, because memory access
is done by the hardware, without any intervention of the OS, and therefore it's too difficult 
to keep track on al lthe accesses.

On the other hand, file access is done using the OS and thus it can keep track on the accesses,
making the management easier.


4) let's say we have a cache of two blocks and three files - f1, f2, f3 which each take one block, 
and let's say the reading order is:

f1 - f1 - f1 - f1 - f2 - f3 - f1.

In LRU we'll discard f1 before reading f3 and therefore we'll have a total of 4 readings from the 
disc while in LFU it would have been 3.

Now let's say the reading order is:

f1 - f1 - f1 - f1 - f2 - f3 - f2.

In LFU we'll discard f2 before reading f3 and therefore we'll have a total of 4 readings from the 
disc while in LRU it would have been 3.

Now let's say the reading order is:

f1 - f1 - f1 - f1 - f2 - f1 - f3 - f2 

In LFU we'll discard f2 before reading f3 and therefore we'll have a total of 4 readings from the 
disc. Also in LRU we'll discard f2 before reading f3 and therefore we'll have a total of 4 readings 
from the disc. So both of the working patterns don't help at all.

5) the typical page size in the OS is 4096 bytes, so the ideal block-size for this excersize will
be 4096 bytes. 

If we'll use a smaller block-size, the OS read requests will be broken to pieces which would cause
a longer reading time.

If we'l use a larger block size we'll have blocks with free space, causing a cache waste.
